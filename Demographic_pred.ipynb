{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the dataset\n",
    "## Alibaba E-commerce User Behavior Dataset\n",
    "\n",
    "Each row in the dataset represents a **page of 50 items** returned to a user during a session (up to 12 pages per session). The dataset contains **15 columns**, explained below:\n",
    "\n",
    "### ðŸ§¾ Column Descriptions\n",
    "\n",
    "| Column | Name               | Description |\n",
    "|--------|--------------------|-------------|\n",
    "| 4      | `page_id`          | ID of the returned page (0â€“11). Each page contains 50 items. |\n",
    "| 5      | `hour`             | Hour of the request (0â€“23), e.g., 14 = 2 PM. |\n",
    "| 1-3  | `user_profile`     | Tuple of `[age-level, gender, purchase power]` used to represent an anonymous user. |\n",
    "| 6      | `item_positions`   | Positions of each item in the overall session (range: 0â€“600). |\n",
    "| 7â€“9    | `item_predictions` | Predicted values for each item: `[CTR, CVR, price]`. |\n",
    "| 10â€“12  | `user_actions`     | User interactions with each item: `[isClick, isCart, isFav]` (1 or 0 for each). |\n",
    "| 13     | `purchase_amounts` | Amount (in Yuan) spent per item (0.0 = no purchase). |\n",
    "| 14     | `item_feature`     | A powerful numerical feature for each item (used in state representation). |\n",
    "| 15     | `is_terminal`      | Flag indicating if this is the last page viewed by the user (1 = yes, 0 = no). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "\n",
    "To prepare the data for baseline models (lightGBM inthis case)which require fixed-size input vectors rather than sequences, we engineered features by aggregating information across the 50 items within each session. The goal of these features is to summarize key aspects of user behavior and session value:\n",
    "\n",
    "* **Interaction Totals:**\n",
    "    * **Features Added:** Calculated the total count for each key interaction type: `Clicks`, `AddToCarts`, `Wishlists`, and `Purchases`.\n",
    "    * **Rationale:** These counts provide a direct measure of the user's overall engagement level and intent signals within the session. For instance, a high number of `AddToCarts` might indicate strong purchase intent, potentially correlating with the target variables (`age-level`, `gender`, `purchase power`).\n",
    "\n",
    "* **Interaction Position Statistics:**\n",
    "    * **Features Added:** Computed the `Average`, `Minimum`, and `Maximum` position index for items that the user interacted with (e.g., clicked, purchased).\n",
    "    * **Rationale:** This captures *how* the user interacts with the ranked list of items. Behavior might differ significantly if users primarily interact with items at the top (low position index) versus items further down (high position index), reflecting aspects like attention span, decisiveness, or search effort.\n",
    "\n",
    "* **Purchase Value Aggregation:**\n",
    "    * **Features Added:** Calculated the `Sum` and `Average` of `Purchase Amounts` for the session.\n",
    "    * **Rationale:** These metrics directly represent the monetary value generated during the session and provide insight into the user's spending behavior in that context. They are particularly relevant for predicting `purchase power` and may also correlate with other demographic segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing up to 100000 rows from file: www.data...\n",
      "  Processed 10000 lines...\n",
      "  Processed 20000 lines...\n",
      "  Processed 30000 lines...\n",
      "  Processed 40000 lines...\n",
      "  Processed 50000 lines...\n",
      "  Processed 60000 lines...\n",
      "  Processed 70000 lines...\n",
      "  Processed 80000 lines...\n",
      "  Processed 90000 lines...\n",
      "  Processed 100000 lines...\n",
      "\n",
      "Reached row limit (100000). Stopping file reading.\n",
      "\n",
      "Finished processing.\n",
      "Attempted to read: 100001 lines (up to limit of 100000)\n",
      "Successfully processed rows: 100000\n",
      "Skipped rows (due to errors, formatting, or empty): 0\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 33 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   age_level              100000 non-null  int64  \n",
      " 1   gender                 100000 non-null  int64  \n",
      " 2   purchasing_power       100000 non-null  int64  \n",
      " 3   page_id                100000 non-null  int64  \n",
      " 4   hour                   100000 non-null  int64  \n",
      " 5   terminal_flag          100000 non-null  int64  \n",
      " 6   total_clicks           100000 non-null  int64  \n",
      " 7   click_rate             100000 non-null  float64\n",
      " 8   any_clicks             100000 non-null  int64  \n",
      " 9   avg_pos_clicked        100000 non-null  float64\n",
      " 10  min_pos_clicked        100000 non-null  int64  \n",
      " 11  max_pos_clicked        100000 non-null  int64  \n",
      " 12  std_pos_clicked        100000 non-null  float64\n",
      " 13  total_add_to_carts     100000 non-null  int64  \n",
      " 14  any_add_to_carts       100000 non-null  int64  \n",
      " 15  avg_pos_added          100000 non-null  float64\n",
      " 16  min_pos_added          100000 non-null  int64  \n",
      " 17  max_pos_added          100000 non-null  int64  \n",
      " 18  std_pos_added          100000 non-null  float64\n",
      " 19  total_wishlists        100000 non-null  int64  \n",
      " 20  any_wishlists          100000 non-null  int64  \n",
      " 21  avg_pos_wishlisted     100000 non-null  float64\n",
      " 22  min_pos_wishlisted     100000 non-null  int64  \n",
      " 23  max_pos_wishlisted     100000 non-null  int64  \n",
      " 24  std_pos_wishlisted     100000 non-null  float64\n",
      " 25  total_items_purchased  100000 non-null  int64  \n",
      " 26  any_purchases          100000 non-null  int64  \n",
      " 27  total_purchase_amount  100000 non-null  float64\n",
      " 28  avg_purchase_amount    100000 non-null  float64\n",
      " 29  avg_pos_purchased      100000 non-null  float64\n",
      " 30  min_pos_purchased      100000 non-null  int64  \n",
      " 31  max_pos_purchased      100000 non-null  int64  \n",
      " 32  std_pos_purchased      100000 non-null  float64\n",
      "dtypes: float64(11), int64(22)\n",
      "memory usage: 25.2 MB\n",
      "\n",
      "DataFrame Head (first 5 rows):\n",
      "   age_level  gender  purchasing_power  page_id  hour  terminal_flag  \\\n",
      "0          6       2                 6        1    17              0   \n",
      "1          6       2                 4        0    22              0   \n",
      "2          5       2                 6        9     7              0   \n",
      "3          5       2                 6        7    21              0   \n",
      "4          6       2                 5        1    20              0   \n",
      "\n",
      "   total_clicks  click_rate  any_clicks  avg_pos_clicked  ...  \\\n",
      "0             0        0.00           0             -1.0  ...   \n",
      "1             0        0.00           0             -1.0  ...   \n",
      "2             1        0.02           1            497.0  ...   \n",
      "3             0        0.00           0             -1.0  ...   \n",
      "4             0        0.00           0             -1.0  ...   \n",
      "\n",
      "   max_pos_wishlisted  std_pos_wishlisted  total_items_purchased  \\\n",
      "0                  -1                -1.0                      0   \n",
      "1                   8                 0.0                      0   \n",
      "2                  -1                -1.0                      0   \n",
      "3                  -1                -1.0                      0   \n",
      "4                  -1                -1.0                      0   \n",
      "\n",
      "   any_purchases  total_purchase_amount  avg_purchase_amount  \\\n",
      "0              0                    0.0                  0.0   \n",
      "1              0                    0.0                  0.0   \n",
      "2              0                    0.0                  0.0   \n",
      "3              0                    0.0                  0.0   \n",
      "4              0                    0.0                  0.0   \n",
      "\n",
      "   avg_pos_purchased  min_pos_purchased  max_pos_purchased  std_pos_purchased  \n",
      "0               -1.0                 -1                 -1               -1.0  \n",
      "1               -1.0                 -1                 -1               -1.0  \n",
      "2               -1.0                 -1                 -1               -1.0  \n",
      "3               -1.0                 -1                 -1               -1.0  \n",
      "4               -1.0                 -1                 -1               -1.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "\n",
      "DataFrame Description (basic stats):\n",
      "          age_level         gender  purchasing_power       page_id  \\\n",
      "count  100000.00000  100000.000000     100000.000000  100000.00000   \n",
      "mean        4.33837       1.744190          3.666450       2.66308   \n",
      "std         1.55243       0.448702          1.720309       2.89545   \n",
      "min         0.00000       0.000000          0.000000       0.00000   \n",
      "25%         3.00000       1.000000          2.000000       0.00000   \n",
      "50%         4.00000       2.000000          4.000000       2.00000   \n",
      "75%         5.00000       2.000000          5.000000       4.00000   \n",
      "max         8.00000       2.000000          7.000000      11.00000   \n",
      "\n",
      "                hour  terminal_flag   total_clicks     click_rate  \\\n",
      "count  100000.000000       100000.0  100000.000000  100000.000000   \n",
      "mean       14.194150            0.0       1.257880       0.025158   \n",
      "std         6.185908            0.0       1.659405       0.033188   \n",
      "min         0.000000            0.0       0.000000       0.000000   \n",
      "25%        10.000000            0.0       0.000000       0.000000   \n",
      "50%        15.000000            0.0       1.000000       0.020000   \n",
      "75%        20.000000            0.0       2.000000       0.040000   \n",
      "max        23.000000            0.0      20.000000       0.400000   \n",
      "\n",
      "          any_clicks  avg_pos_clicked  ...  max_pos_wishlisted  \\\n",
      "count  100000.000000    100000.000000  ...       100000.000000   \n",
      "mean        0.571570        78.016033  ...            6.193650   \n",
      "std         0.494854       123.296010  ...           41.958892   \n",
      "min         0.000000        -1.000000  ...           -1.000000   \n",
      "25%         0.000000        -1.000000  ...           -1.000000   \n",
      "50%         1.000000        13.000000  ...           -1.000000   \n",
      "75%         1.000000       116.000000  ...           -1.000000   \n",
      "max         1.000000       599.000000  ...          598.000000   \n",
      "\n",
      "       std_pos_wishlisted  total_items_purchased  any_purchases  \\\n",
      "count       100000.000000          100000.000000  100000.000000   \n",
      "mean            -0.829312               0.006830       0.005840   \n",
      "std              1.235633               0.099315       0.076197   \n",
      "min             -1.000000               0.000000       0.000000   \n",
      "25%             -1.000000               0.000000       0.000000   \n",
      "50%             -1.000000               0.000000       0.000000   \n",
      "75%             -1.000000               0.000000       0.000000   \n",
      "max             23.500000               8.000000       1.000000   \n",
      "\n",
      "       total_purchase_amount  avg_purchase_amount  avg_pos_purchased  \\\n",
      "count          100000.000000        100000.000000      100000.000000   \n",
      "mean                0.471917             0.400254          -0.513367   \n",
      "std                10.601765             8.704418          10.352911   \n",
      "min                 0.000000             0.000000          -1.000000   \n",
      "25%                 0.000000             0.000000          -1.000000   \n",
      "50%                 0.000000             0.000000          -1.000000   \n",
      "75%                 0.000000             0.000000          -1.000000   \n",
      "max               999.000000           999.000000         563.000000   \n",
      "\n",
      "       min_pos_purchased  max_pos_purchased  std_pos_purchased  \n",
      "count      100000.000000      100000.000000      100000.000000  \n",
      "mean           -0.514140          -0.512610          -0.993419  \n",
      "std            10.345443          10.361059           0.118453  \n",
      "min            -1.000000          -1.000000          -1.000000  \n",
      "25%            -1.000000          -1.000000          -1.000000  \n",
      "50%            -1.000000          -1.000000          -1.000000  \n",
      "75%            -1.000000          -1.000000          -1.000000  \n",
      "max           563.000000         563.000000          14.142136  \n",
      "\n",
      "[8 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "def engineer_features_from_row(row_string):\n",
    "    \n",
    "    try:\n",
    "        fields = row_string.strip().split(';')\n",
    "        if len(fields) != 15:\n",
    "           \n",
    "            return None \n",
    "\n",
    "        #  Parse Original Features \n",
    "        age_level = int(fields[0])\n",
    "        gender = int(fields[1])\n",
    "        purchasing_power = int(fields[2])\n",
    "        page_id = int(fields[3]) \n",
    "        hour = int(fields[4])\n",
    "        terminal_flag = int(fields[14]) \n",
    "\n",
    "        # Parse comma-separated lists\n",
    "        item_positions_str = fields[5].split(',')\n",
    "        clicks_str = fields[9].split(',')\n",
    "        add_to_carts_str = fields[10].split(',')\n",
    "        wishlists_str = fields[11].split(',')\n",
    "        purchase_amounts_str = fields[12].split(',')\n",
    "\n",
    "       \n",
    "        if not all([item_positions_str, clicks_str, add_to_carts_str, wishlists_str, purchase_amounts_str]):\n",
    "           \n",
    "             return None\n",
    "\n",
    "        item_positions = [int(x) for x in item_positions_str]\n",
    "        clicks = [int(x) for x in clicks_str]\n",
    "        add_to_carts = [int(x) for x in add_to_carts_str]\n",
    "        wishlists = [int(x) for x in wishlists_str]\n",
    "        purchase_amounts = [float(x) for x in purchase_amounts_str]\n",
    "\n",
    "        \n",
    "        list_len = len(item_positions)\n",
    "        if list_len == 0 or not all(len(lst) == list_len for lst in [clicks, add_to_carts, wishlists, purchase_amounts]):\n",
    "            \n",
    "             return None\n",
    "\n",
    "        #  Feature Engineering \n",
    "        features = {\n",
    "            'age_level': age_level,\n",
    "            'gender': gender,\n",
    "            'purchasing_power': purchasing_power,\n",
    "            'page_id': page_id,\n",
    "            'hour': hour,\n",
    "            'terminal_flag': terminal_flag\n",
    "        }\n",
    "\n",
    "        # Click-Based Features\n",
    "        total_clicks = sum(clicks)\n",
    "        features['total_clicks'] = total_clicks\n",
    "        features['click_rate'] = total_clicks / list_len\n",
    "        features['any_clicks'] = 1 if total_clicks > 0 else 0\n",
    "\n",
    "        clicked_positions = [pos for pos, click in zip(item_positions, clicks) if click == 1]\n",
    "        if total_clicks > 0:\n",
    "            features['avg_pos_clicked'] = np.mean(clicked_positions)\n",
    "            features['min_pos_clicked'] = np.min(clicked_positions)\n",
    "            features['max_pos_clicked'] = np.max(clicked_positions)\n",
    "            features['std_pos_clicked'] = np.std(clicked_positions) if total_clicks > 1 else 0.0\n",
    "        else:\n",
    "            features['avg_pos_clicked'] = -1.0\n",
    "            features['min_pos_clicked'] = -1\n",
    "            features['max_pos_clicked'] = -1\n",
    "            features['std_pos_clicked'] = -1.0\n",
    "\n",
    "        # Add-to-Cart-Based Features\n",
    "        total_add_to_carts = sum(add_to_carts)\n",
    "        features['total_add_to_carts'] = total_add_to_carts\n",
    "        features['any_add_to_carts'] = 1 if total_add_to_carts > 0 else 0\n",
    "\n",
    "        added_positions = [pos for pos, add in zip(item_positions, add_to_carts) if add == 1]\n",
    "        if total_add_to_carts > 0:\n",
    "            features['avg_pos_added'] = np.mean(added_positions)\n",
    "            features['min_pos_added'] = np.min(added_positions)\n",
    "            features['max_pos_added'] = np.max(added_positions)\n",
    "            features['std_pos_added'] = np.std(added_positions) if total_add_to_carts > 1 else 0.0\n",
    "        else:\n",
    "            features['avg_pos_added'] = -1.0\n",
    "            features['min_pos_added'] = -1\n",
    "            features['max_pos_added'] = -1\n",
    "            features['std_pos_added'] = -1.0\n",
    "\n",
    "        #  Wishlist-Based Features\n",
    "        total_wishlists = sum(wishlists)\n",
    "        features['total_wishlists'] = total_wishlists\n",
    "        features['any_wishlists'] = 1 if total_wishlists > 0 else 0\n",
    "\n",
    "        wishlisted_positions = [pos for pos, wish in zip(item_positions, wishlists) if wish == 1]\n",
    "        if total_wishlists > 0:\n",
    "            features['avg_pos_wishlisted'] = np.mean(wishlisted_positions)\n",
    "            features['min_pos_wishlisted'] = np.min(wishlisted_positions)\n",
    "            features['max_pos_wishlisted'] = np.max(wishlisted_positions)\n",
    "            features['std_pos_wishlisted'] = np.std(wishlisted_positions) if total_wishlists > 1 else 0.0\n",
    "        else:\n",
    "            features['avg_pos_wishlisted'] = -1.0\n",
    "            features['min_pos_wishlisted'] = -1\n",
    "            features['max_pos_wishlisted'] = -1\n",
    "            features['std_pos_wishlisted'] = -1.0\n",
    "\n",
    "        #  Purchase-Based Features\n",
    "        purchased_items_info = [(pos, amount) for pos, amount in zip(item_positions, purchase_amounts) if amount > 0]\n",
    "        total_items_purchased = len(purchased_items_info)\n",
    "        features['total_items_purchased'] = total_items_purchased\n",
    "        features['any_purchases'] = 1 if total_items_purchased > 0 else 0\n",
    "\n",
    "        if total_items_purchased > 0:\n",
    "            purchased_positions = [item[0] for item in purchased_items_info]\n",
    "            purchase_values = [item[1] for item in purchased_items_info]\n",
    "            features['total_purchase_amount'] = np.sum(purchase_values)\n",
    "            features['avg_purchase_amount'] = np.mean(purchase_values)\n",
    "            features['avg_pos_purchased'] = np.mean(purchased_positions)\n",
    "            features['min_pos_purchased'] = np.min(purchased_positions)\n",
    "            features['max_pos_purchased'] = np.max(purchased_positions)\n",
    "            features['std_pos_purchased'] = np.std(purchased_positions) if total_items_purchased > 1 else 0.0\n",
    "        else:\n",
    "            features['total_purchase_amount'] = 0.0\n",
    "            features['avg_purchase_amount'] = 0.0 # Or -1.0 or np.nan\n",
    "            features['avg_pos_purchased'] = -1.0\n",
    "            features['min_pos_purchased'] = -1\n",
    "            features['max_pos_purchased'] = -1\n",
    "            features['std_pos_purchased'] = -1.0\n",
    "\n",
    "        return features\n",
    "\n",
    "    except ValueError as ve:\n",
    "       \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return None \n",
    "\n",
    "file_path = 'www.data'\n",
    "all_engineered_data = []\n",
    "rows_processed = 0\n",
    "rows_skipped = 0\n",
    "row_limit=100000\n",
    "\n",
    "print(f\"Processing up to {row_limit} rows from file: {file_path}...\")\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Use enumerate to get row index (starts from 0)\n",
    "        for i, line in enumerate(f):\n",
    "            # Stop if the row limit is reached\n",
    "            if i >= row_limit:\n",
    "                print(f\"\\nReached row limit ({row_limit}). Stopping file reading.\")\n",
    "                break\n",
    "\n",
    "            \n",
    "            if not line.strip():\n",
    "                rows_skipped += 1\n",
    "                continue\n",
    "\n",
    "            engineered_row_data = engineer_features_from_row(line)\n",
    "\n",
    "            if engineered_row_data:\n",
    "                all_engineered_data.append(engineered_row_data)\n",
    "                rows_processed += 1\n",
    "            else:\n",
    "               \n",
    "                rows_skipped += 1\n",
    "\n",
    "            \n",
    "            if (i + 1) % 10000 == 0:\n",
    "                print(f\"  Processed {i+1} lines...\")\n",
    "\n",
    "\n",
    "    print(f\"\\nFinished processing.\")\n",
    "    print(f\"Attempted to read: {i+1 if 'i' in locals() else 0} lines (up to limit of {row_limit})\") # Check if loop ran at all\n",
    "    print(f\"Successfully processed rows: {rows_processed}\")\n",
    "    print(f\"Skipped rows (due to errors, formatting, or empty): {rows_skipped}\")\n",
    "\n",
    "    # Convert the list of dictionaries into a Pandas DataFrame\n",
    "    if all_engineered_data:\n",
    "        df = pd.DataFrame(all_engineered_data)\n",
    "\n",
    "        print(\"\\nDataFrame Info:\")\n",
    "        df.info() \n",
    "\n",
    "        print(\"\\nDataFrame Head (first 5 rows):\")\n",
    "        print(df.head())\n",
    "\n",
    "        print(\"\\nDataFrame Description (basic stats):\")\n",
    "        print(df.describe())\n",
    "\n",
    "        \n",
    "\n",
    "    elif rows_processed == 0:\n",
    "        print(\"\\nNo valid rows were processed from the first {row_limit} lines (or file was smaller/empty).\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during file processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>purchasing_power</th>\n",
       "      <th>page_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>terminal_flag</th>\n",
       "      <th>total_clicks</th>\n",
       "      <th>click_rate</th>\n",
       "      <th>any_clicks</th>\n",
       "      <th>avg_pos_clicked</th>\n",
       "      <th>...</th>\n",
       "      <th>max_pos_wishlisted</th>\n",
       "      <th>std_pos_wishlisted</th>\n",
       "      <th>total_items_purchased</th>\n",
       "      <th>any_purchases</th>\n",
       "      <th>total_purchase_amount</th>\n",
       "      <th>avg_purchase_amount</th>\n",
       "      <th>avg_pos_purchased</th>\n",
       "      <th>min_pos_purchased</th>\n",
       "      <th>max_pos_purchased</th>\n",
       "      <th>std_pos_purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>311.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_level  gender  purchasing_power  page_id  hour  terminal_flag  \\\n",
       "0              6       2                 6        1    17              0   \n",
       "1              6       2                 4        0    22              0   \n",
       "2              5       2                 6        9     7              0   \n",
       "3              5       2                 6        7    21              0   \n",
       "4              6       2                 5        1    20              0   \n",
       "...          ...     ...               ...      ...   ...            ...   \n",
       "99995          4       2                 2        2     7              0   \n",
       "99996          4       2                 2        6    15              0   \n",
       "99997          7       1                 6        0    16              0   \n",
       "99998          5       2                 6        1     7              0   \n",
       "99999          7       1                 3        1    17              0   \n",
       "\n",
       "       total_clicks  click_rate  any_clicks  avg_pos_clicked  ...  \\\n",
       "0                 0        0.00           0        -1.000000  ...   \n",
       "1                 0        0.00           0        -1.000000  ...   \n",
       "2                 1        0.02           1       497.000000  ...   \n",
       "3                 0        0.00           0        -1.000000  ...   \n",
       "4                 0        0.00           0        -1.000000  ...   \n",
       "...             ...         ...         ...              ...  ...   \n",
       "99995             3        0.06           1       128.000000  ...   \n",
       "99996             3        0.06           1       311.333333  ...   \n",
       "99997             2        0.04           1        10.000000  ...   \n",
       "99998             1        0.02           1        53.000000  ...   \n",
       "99999             3        0.06           1        91.666667  ...   \n",
       "\n",
       "       max_pos_wishlisted  std_pos_wishlisted  total_items_purchased  \\\n",
       "0                      -1                -1.0                      0   \n",
       "1                       8                 0.0                      0   \n",
       "2                      -1                -1.0                      0   \n",
       "3                      -1                -1.0                      0   \n",
       "4                      -1                -1.0                      0   \n",
       "...                   ...                 ...                    ...   \n",
       "99995                  -1                -1.0                      0   \n",
       "99996                  -1                -1.0                      0   \n",
       "99997                  -1                -1.0                      0   \n",
       "99998                  -1                -1.0                      0   \n",
       "99999                  -1                -1.0                      0   \n",
       "\n",
       "       any_purchases  total_purchase_amount  avg_purchase_amount  \\\n",
       "0                  0                    0.0                  0.0   \n",
       "1                  0                    0.0                  0.0   \n",
       "2                  0                    0.0                  0.0   \n",
       "3                  0                    0.0                  0.0   \n",
       "4                  0                    0.0                  0.0   \n",
       "...              ...                    ...                  ...   \n",
       "99995              0                    0.0                  0.0   \n",
       "99996              0                    0.0                  0.0   \n",
       "99997              0                    0.0                  0.0   \n",
       "99998              0                    0.0                  0.0   \n",
       "99999              0                    0.0                  0.0   \n",
       "\n",
       "       avg_pos_purchased  min_pos_purchased  max_pos_purchased  \\\n",
       "0                   -1.0                 -1                 -1   \n",
       "1                   -1.0                 -1                 -1   \n",
       "2                   -1.0                 -1                 -1   \n",
       "3                   -1.0                 -1                 -1   \n",
       "4                   -1.0                 -1                 -1   \n",
       "...                  ...                ...                ...   \n",
       "99995               -1.0                 -1                 -1   \n",
       "99996               -1.0                 -1                 -1   \n",
       "99997               -1.0                 -1                 -1   \n",
       "99998               -1.0                 -1                 -1   \n",
       "99999               -1.0                 -1                 -1   \n",
       "\n",
       "       std_pos_purchased  \n",
       "0                   -1.0  \n",
       "1                   -1.0  \n",
       "2                   -1.0  \n",
       "3                   -1.0  \n",
       "4                   -1.0  \n",
       "...                  ...  \n",
       "99995               -1.0  \n",
       "99996               -1.0  \n",
       "99997               -1.0  \n",
       "99998               -1.0  \n",
       "99999               -1.0  \n",
       "\n",
       "[100000 rows x 33 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "       age_level  gender  purchasing_power  page_id  hour  terminal_flag  \\\n",
      "0              6       2                 6        1    17              0   \n",
      "1              6       2                 4        0    22              0   \n",
      "2              5       2                 6        9     7              0   \n",
      "3              5       2                 6        7    21              0   \n",
      "4              6       2                 5        1    20              0   \n",
      "...          ...     ...               ...      ...   ...            ...   \n",
      "99995          4       2                 2        2     7              0   \n",
      "99996          4       2                 2        6    15              0   \n",
      "99997          7       1                 6        0    16              0   \n",
      "99998          5       2                 6        1     7              0   \n",
      "99999          7       1                 3        1    17              0   \n",
      "\n",
      "       total_clicks  click_rate  any_clicks  avg_pos_clicked  ...  \\\n",
      "0                 0        0.00           0        -1.000000  ...   \n",
      "1                 0        0.00           0        -1.000000  ...   \n",
      "2                 1        0.02           1       497.000000  ...   \n",
      "3                 0        0.00           0        -1.000000  ...   \n",
      "4                 0        0.00           0        -1.000000  ...   \n",
      "...             ...         ...         ...              ...  ...   \n",
      "99995             3        0.06           1       128.000000  ...   \n",
      "99996             3        0.06           1       311.333333  ...   \n",
      "99997             2        0.04           1        10.000000  ...   \n",
      "99998             1        0.02           1        53.000000  ...   \n",
      "99999             3        0.06           1        91.666667  ...   \n",
      "\n",
      "       max_pos_wishlisted  std_pos_wishlisted  total_items_purchased  \\\n",
      "0                      -1                -1.0                      0   \n",
      "1                       8                 0.0                      0   \n",
      "2                      -1                -1.0                      0   \n",
      "3                      -1                -1.0                      0   \n",
      "4                      -1                -1.0                      0   \n",
      "...                   ...                 ...                    ...   \n",
      "99995                  -1                -1.0                      0   \n",
      "99996                  -1                -1.0                      0   \n",
      "99997                  -1                -1.0                      0   \n",
      "99998                  -1                -1.0                      0   \n",
      "99999                  -1                -1.0                      0   \n",
      "\n",
      "       any_purchases  total_purchase_amount  avg_purchase_amount  \\\n",
      "0                  0                    0.0                  0.0   \n",
      "1                  0                    0.0                  0.0   \n",
      "2                  0                    0.0                  0.0   \n",
      "3                  0                    0.0                  0.0   \n",
      "4                  0                    0.0                  0.0   \n",
      "...              ...                    ...                  ...   \n",
      "99995              0                    0.0                  0.0   \n",
      "99996              0                    0.0                  0.0   \n",
      "99997              0                    0.0                  0.0   \n",
      "99998              0                    0.0                  0.0   \n",
      "99999              0                    0.0                  0.0   \n",
      "\n",
      "       avg_pos_purchased  min_pos_purchased  max_pos_purchased  \\\n",
      "0                   -1.0                 -1                 -1   \n",
      "1                   -1.0                 -1                 -1   \n",
      "2                   -1.0                 -1                 -1   \n",
      "3                   -1.0                 -1                 -1   \n",
      "4                   -1.0                 -1                 -1   \n",
      "...                  ...                ...                ...   \n",
      "99995               -1.0                 -1                 -1   \n",
      "99996               -1.0                 -1                 -1   \n",
      "99997               -1.0                 -1                 -1   \n",
      "99998               -1.0                 -1                 -1   \n",
      "99999               -1.0                 -1                 -1   \n",
      "\n",
      "       std_pos_purchased  \n",
      "0                   -1.0  \n",
      "1                   -1.0  \n",
      "2                   -1.0  \n",
      "3                   -1.0  \n",
      "4                   -1.0  \n",
      "...                  ...  \n",
      "99995               -1.0  \n",
      "99996               -1.0  \n",
      "99997               -1.0  \n",
      "99998               -1.0  \n",
      "99999               -1.0  \n",
      "\n",
      "[100000 rows x 33 columns]\n",
      "\n",
      "DataFrame after One-Hot Encoding:\n",
      "       age_level  gender  purchasing_power  hour  terminal_flag  total_clicks  \\\n",
      "0              6       2                 6    17              0             0   \n",
      "1              6       2                 4    22              0             0   \n",
      "2              5       2                 6     7              0             1   \n",
      "3              5       2                 6    21              0             0   \n",
      "4              6       2                 5    20              0             0   \n",
      "...          ...     ...               ...   ...            ...           ...   \n",
      "99995          4       2                 2     7              0             3   \n",
      "99996          4       2                 2    15              0             3   \n",
      "99997          7       1                 6    16              0             2   \n",
      "99998          5       2                 6     7              0             1   \n",
      "99999          7       1                 3    17              0             3   \n",
      "\n",
      "       click_rate  any_clicks  avg_pos_clicked  min_pos_clicked  ...  \\\n",
      "0            0.00           0        -1.000000               -1  ...   \n",
      "1            0.00           0        -1.000000               -1  ...   \n",
      "2            0.02           1       497.000000              497  ...   \n",
      "3            0.00           0        -1.000000               -1  ...   \n",
      "4            0.00           0        -1.000000               -1  ...   \n",
      "...           ...         ...              ...              ...  ...   \n",
      "99995        0.06           1       128.000000              122  ...   \n",
      "99996        0.06           1       311.333333              304  ...   \n",
      "99997        0.04           1        10.000000                9  ...   \n",
      "99998        0.02           1        53.000000               53  ...   \n",
      "99999        0.06           1        91.666667               88  ...   \n",
      "\n",
      "       page_id_2  page_id_3  page_id_4  page_id_5  page_id_6  page_id_7  \\\n",
      "0          False      False      False      False      False      False   \n",
      "1          False      False      False      False      False      False   \n",
      "2          False      False      False      False      False      False   \n",
      "3          False      False      False      False      False       True   \n",
      "4          False      False      False      False      False      False   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "99995       True      False      False      False      False      False   \n",
      "99996      False      False      False      False       True      False   \n",
      "99997      False      False      False      False      False      False   \n",
      "99998      False      False      False      False      False      False   \n",
      "99999      False      False      False      False      False      False   \n",
      "\n",
      "       page_id_8  page_id_9  page_id_10  page_id_11  \n",
      "0          False      False       False       False  \n",
      "1          False      False       False       False  \n",
      "2          False       True       False       False  \n",
      "3          False      False       False       False  \n",
      "4          False      False       False       False  \n",
      "...          ...        ...         ...         ...  \n",
      "99995      False      False       False       False  \n",
      "99996      False      False       False       False  \n",
      "99997      False      False       False       False  \n",
      "99998      False      False       False       False  \n",
      "99999      False      False       False       False  \n",
      "\n",
      "[100000 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_to_encode = 'page_id'\n",
    "\n",
    "# Perform one-hot encoding on page_id\n",
    "encoded_df = pd.get_dummies(df, columns=[feature_to_encode], prefix=feature_to_encode)\n",
    "\n",
    "# Display the result\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame after One-Hot Encoding:\")\n",
    "\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df['page_id']=df['page_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>purchasing_power</th>\n",
       "      <th>hour</th>\n",
       "      <th>terminal_flag</th>\n",
       "      <th>total_clicks</th>\n",
       "      <th>click_rate</th>\n",
       "      <th>any_clicks</th>\n",
       "      <th>avg_pos_clicked</th>\n",
       "      <th>min_pos_clicked</th>\n",
       "      <th>...</th>\n",
       "      <th>page_id_3</th>\n",
       "      <th>page_id_4</th>\n",
       "      <th>page_id_5</th>\n",
       "      <th>page_id_6</th>\n",
       "      <th>page_id_7</th>\n",
       "      <th>page_id_8</th>\n",
       "      <th>page_id_9</th>\n",
       "      <th>page_id_10</th>\n",
       "      <th>page_id_11</th>\n",
       "      <th>page_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_level  gender  purchasing_power  hour  terminal_flag  total_clicks  \\\n",
       "0          6       2                 6    17              0             0   \n",
       "1          6       2                 4    22              0             0   \n",
       "\n",
       "   click_rate  any_clicks  avg_pos_clicked  min_pos_clicked  ...  page_id_3  \\\n",
       "0         0.0           0             -1.0               -1  ...      False   \n",
       "1         0.0           0             -1.0               -1  ...      False   \n",
       "\n",
       "   page_id_4  page_id_5  page_id_6  page_id_7  page_id_8  page_id_9  \\\n",
       "0      False      False      False      False      False      False   \n",
       "1      False      False      False      False      False      False   \n",
       "\n",
       "   page_id_10  page_id_11  page_id  \n",
       "0       False       False        1  \n",
       "1       False       False        0  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_level', 'gender', 'purchasing_power', 'hour', 'terminal_flag',\n",
       "       'total_clicks', 'click_rate', 'any_clicks', 'avg_pos_clicked',\n",
       "       'min_pos_clicked', 'max_pos_clicked', 'std_pos_clicked',\n",
       "       'total_add_to_carts', 'any_add_to_carts', 'avg_pos_added',\n",
       "       'min_pos_added', 'max_pos_added', 'std_pos_added', 'total_wishlists',\n",
       "       'any_wishlists', 'avg_pos_wishlisted', 'min_pos_wishlisted',\n",
       "       'max_pos_wishlisted', 'std_pos_wishlisted', 'total_items_purchased',\n",
       "       'any_purchases', 'total_purchase_amount', 'avg_purchase_amount',\n",
       "       'avg_pos_purchased', 'min_pos_purchased', 'max_pos_purchased',\n",
       "       'std_pos_purchased', 'page_id_0', 'page_id_1', 'page_id_2', 'page_id_3',\n",
       "       'page_id_4', 'page_id_5', 'page_id_6', 'page_id_7', 'page_id_8',\n",
       "       'page_id_9', 'page_id_10', 'page_id_11', 'page_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the below mentioned columns to be between 1 and 50 so that the algorithm can find appropriate relations\n",
    "\n",
    "\n",
    "cols_to_update = [\n",
    "    'avg_pos_clicked', 'min_pos_clicked', 'max_pos_clicked',\n",
    "    'avg_pos_added', 'min_pos_added', 'max_pos_added',\n",
    "    'avg_pos_wishlisted', 'min_pos_wishlisted', 'max_pos_wishlisted',\n",
    "    'avg_purchase_amount', 'avg_pos_purchased', 'std_pos_purchased', 'min_pos_purchased','max_pos_purchased',\n",
    "]\n",
    "\n",
    "for col in cols_to_update:\n",
    "    encoded_df[f'{col}_1'] = encoded_df.apply(\n",
    "        lambda row: row[col] - 50 * row['page_id'] if row[col] not in [0, -1] else row[col],\n",
    "        axis=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.drop(['terminal_flag'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 58 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   age_level              100000 non-null  int64  \n",
      " 1   gender                 100000 non-null  int64  \n",
      " 2   purchasing_power       100000 non-null  int64  \n",
      " 3   hour                   100000 non-null  int64  \n",
      " 4   total_clicks           100000 non-null  int64  \n",
      " 5   click_rate             100000 non-null  float64\n",
      " 6   any_clicks             100000 non-null  int64  \n",
      " 7   avg_pos_clicked        100000 non-null  float64\n",
      " 8   min_pos_clicked        100000 non-null  int64  \n",
      " 9   max_pos_clicked        100000 non-null  int64  \n",
      " 10  std_pos_clicked        100000 non-null  float64\n",
      " 11  total_add_to_carts     100000 non-null  int64  \n",
      " 12  any_add_to_carts       100000 non-null  int64  \n",
      " 13  avg_pos_added          100000 non-null  float64\n",
      " 14  min_pos_added          100000 non-null  int64  \n",
      " 15  max_pos_added          100000 non-null  int64  \n",
      " 16  std_pos_added          100000 non-null  float64\n",
      " 17  total_wishlists        100000 non-null  int64  \n",
      " 18  any_wishlists          100000 non-null  int64  \n",
      " 19  avg_pos_wishlisted     100000 non-null  float64\n",
      " 20  min_pos_wishlisted     100000 non-null  int64  \n",
      " 21  max_pos_wishlisted     100000 non-null  int64  \n",
      " 22  std_pos_wishlisted     100000 non-null  float64\n",
      " 23  total_items_purchased  100000 non-null  int64  \n",
      " 24  any_purchases          100000 non-null  int64  \n",
      " 25  total_purchase_amount  100000 non-null  float64\n",
      " 26  avg_purchase_amount    100000 non-null  float64\n",
      " 27  avg_pos_purchased      100000 non-null  float64\n",
      " 28  min_pos_purchased      100000 non-null  int64  \n",
      " 29  max_pos_purchased      100000 non-null  int64  \n",
      " 30  std_pos_purchased      100000 non-null  float64\n",
      " 31  page_id_0              100000 non-null  bool   \n",
      " 32  page_id_1              100000 non-null  bool   \n",
      " 33  page_id_2              100000 non-null  bool   \n",
      " 34  page_id_3              100000 non-null  bool   \n",
      " 35  page_id_4              100000 non-null  bool   \n",
      " 36  page_id_5              100000 non-null  bool   \n",
      " 37  page_id_6              100000 non-null  bool   \n",
      " 38  page_id_7              100000 non-null  bool   \n",
      " 39  page_id_8              100000 non-null  bool   \n",
      " 40  page_id_9              100000 non-null  bool   \n",
      " 41  page_id_10             100000 non-null  bool   \n",
      " 42  page_id_11             100000 non-null  bool   \n",
      " 43  page_id                100000 non-null  int64  \n",
      " 44  avg_pos_clicked_1      100000 non-null  float64\n",
      " 45  min_pos_clicked_1      100000 non-null  int64  \n",
      " 46  max_pos_clicked_1      100000 non-null  int64  \n",
      " 47  avg_pos_added_1        100000 non-null  float64\n",
      " 48  min_pos_added_1        100000 non-null  int64  \n",
      " 49  max_pos_added_1        100000 non-null  int64  \n",
      " 50  avg_pos_wishlisted_1   100000 non-null  float64\n",
      " 51  min_pos_wishlisted_1   100000 non-null  int64  \n",
      " 52  max_pos_wishlisted_1   100000 non-null  int64  \n",
      " 53  avg_purchase_amount_1  100000 non-null  float64\n",
      " 54  avg_pos_purchased_1    100000 non-null  float64\n",
      " 55  std_pos_purchased_1    100000 non-null  float64\n",
      " 56  min_pos_purchased_1    100000 non-null  int64  \n",
      " 57  max_pos_purchased_1    100000 non-null  int64  \n",
      "dtypes: bool(12), float64(17), int64(29)\n",
      "memory usage: 36.2 MB\n"
     ]
    }
   ],
   "source": [
    "encoded_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM model for classification of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique age levels (classes): 9\n",
      "\n",
      "Original training set shape: X=(80000, 40), y=(80000,)\n",
      "Original training class distribution:\n",
      "age_level\n",
      "0      287\n",
      "1      343\n",
      "2     4586\n",
      "3    24194\n",
      "4    18817\n",
      "5    13076\n",
      "6     8136\n",
      "7     8978\n",
      "8     1583\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set shape: X=(20000, 40), y=(20000,)\n",
      "Test set class distribution:\n",
      "age_level\n",
      "0      72\n",
      "1      85\n",
      "2    1147\n",
      "3    6049\n",
      "4    4704\n",
      "5    3269\n",
      "6    2034\n",
      "7    2245\n",
      "8     395\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Applying SMOTE to the training data...\n",
      "Smallest class size in training set: 287. Setting SMOTE k_neighbors=286\n",
      "\n",
      "Resampled training set shape: X=(217746, 40), y=(217746,)\n",
      "Resampled training class distribution:\n",
      "age_level\n",
      "0    24194\n",
      "1    24194\n",
      "2    24194\n",
      "3    24194\n",
      "4    24194\n",
      "5    24194\n",
      "6    24194\n",
      "7    24194\n",
      "8    24194\n",
      "Name: count, dtype: int64\n",
      "SMOTE applied successfully.\n",
      "\n",
      "Training LightGBM model on RESAMPLED data...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3500\n",
      "[LightGBM] [Info] Number of data points in the train set: 217746, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "[LightGBM] [Info] Start training from score -2.197225\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[548]\tvalid_0's multi_logloss: 1.81734\n",
      "\n",
      "Training complete.\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.2964\n",
      "F1 Score (Micro): 0.2964\n",
      "F1 Score (Macro): 0.0710\n",
      "F1 Score (Weighted): 0.1771\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.00      0.00      0.00        85\n",
      "           2       0.05      0.00      0.00      1147\n",
      "           3       0.31      0.89      0.46      6049\n",
      "           4       0.25      0.10      0.15      4704\n",
      "           5       0.14      0.01      0.02      3269\n",
      "           6       0.14      0.00      0.01      2034\n",
      "           7       0.07      0.00      0.01      2245\n",
      "           8       0.00      0.00      0.00       395\n",
      "\n",
      "    accuracy                           0.30     20000\n",
      "   macro avg       0.11      0.11      0.07     20000\n",
      "weighted avg       0.20      0.30      0.18     20000\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "                 feature  importance\n",
      "0                   hour       16969\n",
      "4      avg_pos_clicked_1       15460\n",
      "7        std_pos_clicked       13759\n",
      "2             click_rate       13026\n",
      "5      min_pos_clicked_1       11009\n",
      "6      max_pos_clicked_1       10232\n",
      "13         std_pos_added        4524\n",
      "10       avg_pos_added_1        4071\n",
      "11       min_pos_added_1        3775\n",
      "19    std_pos_wishlisted        3283\n",
      "29             page_id_1        3072\n",
      "12       max_pos_added_1        3032\n",
      "28             page_id_0        2981\n",
      "30             page_id_2        2944\n",
      "31             page_id_3        2939\n",
      "17  min_pos_wishlisted_1        2859\n",
      "32             page_id_4        2808\n",
      "33             page_id_5        2639\n",
      "1           total_clicks        2501\n",
      "16  avg_pos_wishlisted_1        2498\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Define target and features\n",
    "target_age = 'age_level'\n",
    "features = [\n",
    "    'hour',\n",
    "    'total_clicks', 'click_rate', 'any_clicks', \n",
    "    'avg_pos_clicked_1', 'min_pos_clicked_1', 'max_pos_clicked_1', 'std_pos_clicked',\n",
    "    \n",
    "    'total_add_to_carts', 'any_add_to_carts', \n",
    "    'avg_pos_added_1', 'min_pos_added_1', 'max_pos_added_1', 'std_pos_added',\n",
    "    \n",
    "    'total_wishlists', 'any_wishlists', \n",
    "    'avg_pos_wishlisted_1', 'min_pos_wishlisted_1', 'max_pos_wishlisted_1', 'std_pos_wishlisted',\n",
    "    \n",
    "    'total_items_purchased', 'any_purchases', 'total_purchase_amount',\n",
    "    'avg_purchase_amount_1', 'avg_pos_purchased_1', 'min_pos_purchased_1',\n",
    "    'max_pos_purchased_1', 'std_pos_purchased',\n",
    "    \n",
    "    'page_id_0', 'page_id_1', 'page_id_2', 'page_id_3', 'page_id_4', 'page_id_5',\n",
    "    'page_id_6', 'page_id_7', 'page_id_8', 'page_id_9', 'page_id_10', 'page_id_11'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "X = encoded_df[features]\n",
    "y = encoded_df[target_age]\n",
    "\n",
    "\n",
    "num_classes = y.nunique()\n",
    "print(f\"Number of unique age levels (classes): {num_classes}\")\n",
    "\n",
    "\n",
    "#  Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nOriginal training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Original training class distribution:\\n{y_train.value_counts().sort_index()}\")\n",
    "print(f\"\\nTest set shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"Test set class distribution:\\n{y_test.value_counts().sort_index()}\")\n",
    "\n",
    "\n",
    "#  Apply SMOTE to the Training Data \n",
    "print(\"\\nApplying SMOTE to the training data...\")\n",
    "\n",
    "\n",
    "min_class_size = y_train.value_counts().min()\n",
    "safe_k_neighbors = max(1, min_class_size - 1) \n",
    "\n",
    "print(f\"Smallest class size in training set: {min_class_size}. Setting SMOTE k_neighbors={safe_k_neighbors}\")\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=safe_k_neighbors)\n",
    "\n",
    "try:\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"\\nResampled training set shape: X={X_train_res.shape}, y={y_train_res.shape}\")\n",
    "    print(f\"Resampled training class distribution:\\n{pd.Series(y_train_res).value_counts().sort_index()}\") \n",
    "    print(\"SMOTE applied successfully.\")\n",
    "    use_resampled_data = True\n",
    "except ValueError as e:\n",
    "    print(f\"\\nSMOTE Error: {e}\")\n",
    "    print(\"Could not apply SMOTE (likely too few samples in a minority class).\")\n",
    "    print(\"Proceeding with original training data. Consider adding 'class_weight=\\'balanced\\'' back to LGBMClassifier if using original data.\")\n",
    "    X_train_res, y_train_res = X_train, y_train \n",
    "    use_resampled_data = False\n",
    "\n",
    "\n",
    "#  Initialize and Train LightGBM Model (without class_weight) \n",
    "# Use slightly increased patience and estimators as SMOTE might need more training\n",
    "lgbm_classifier = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=num_classes,\n",
    "    metric='multi_logloss',\n",
    "    n_estimators=6000,          \n",
    "    learning_rate=0.04,\n",
    "    num_leaves=31,               \n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1\n",
    "    \n",
    ")\n",
    "\n",
    "# Add class_weight back if SMOTE failed and we fell back to original data\n",
    "if not use_resampled_data:\n",
    "    print(\"\\nSMOTE failed, adding class_weight='balanced' to the model.\")\n",
    "    lgbm_classifier.set_params(class_weight='balanced')\n",
    "\n",
    "\n",
    "print(f\"\\nTraining LightGBM model {'on RESAMPLED data' if use_resampled_data else 'on ORIGINAL data (with weighting if SMOTE failed)'}...\")\n",
    "\n",
    "# Train the model using the (potentially) resampled training data\n",
    "lgbm_classifier.fit(\n",
    "    X_train_res, y_train_res,\n",
    "    eval_set=[(X_test, y_test)], \n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=150, verbose=True)] # Increased patience\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "\n",
    "# Make Predictions on the Original Test Set \n",
    "print(\"\\nMaking predictions on the test set...\")\n",
    "y_pred = lgbm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the Model \n",
    "print(\"\\nEvaluating the model...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (Micro): {f1_micro:.4f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\nFeature Importances:\")\n",
    "  \n",
    "if isinstance(X_train_res, np.ndarray):\n",
    "    feature_names = X_train.columns \n",
    "else:\n",
    "     feature_names = X_train_res.columns \n",
    "\n",
    "feature_imp = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': lgbm_classifier.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_imp.head(20)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Light GBM for purchasing power prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique age levels (classes): 8\n",
      "\n",
      "Original training set shape: X=(80000, 40), y=(80000,)\n",
      "Original training class distribution:\n",
      "purchasing_power\n",
      "0     3123\n",
      "1     5152\n",
      "2    12576\n",
      "3    16018\n",
      "4    17150\n",
      "5    13356\n",
      "6     8798\n",
      "7     3827\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set shape: X=(20000, 40), y=(20000,)\n",
      "Test set class distribution:\n",
      "purchasing_power\n",
      "0     781\n",
      "1    1288\n",
      "2    3144\n",
      "3    4004\n",
      "4    4287\n",
      "5    3339\n",
      "6    2200\n",
      "7     957\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Applying SMOTE to the training data...\n",
      "Smallest class size in training set: 3123. Setting SMOTE k_neighbors=3122\n",
      "\n",
      "Resampled training set shape: X=(137200, 40), y=(137200,)\n",
      "Resampled training class distribution:\n",
      "purchasing_power\n",
      "0    17150\n",
      "1    17150\n",
      "2    17150\n",
      "3    17150\n",
      "4    17150\n",
      "5    17150\n",
      "6    17150\n",
      "7    17150\n",
      "Name: count, dtype: int64\n",
      "SMOTE applied successfully.\n",
      "\n",
      "Training LightGBM model on RESAMPLED data...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3496\n",
      "[LightGBM] [Info] Number of data points in the train set: 137200, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "[LightGBM] [Info] Start training from score -2.079442\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 1.94846\n",
      "\n",
      "Training complete.\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "Evaluating the model...\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.2104\n",
      "F1 Score (Micro): 0.2104\n",
      "F1 Score (Macro): 0.0737\n",
      "F1 Score (Weighted): 0.1201\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       781\n",
      "           1       0.20      0.00      0.00      1288\n",
      "           2       0.13      0.01      0.02      3144\n",
      "           3       0.21      0.21      0.21      4004\n",
      "           4       0.21      0.77      0.33      4287\n",
      "           5       0.16      0.01      0.02      3339\n",
      "           6       0.14      0.01      0.01      2200\n",
      "           7       0.00      0.00      0.00       957\n",
      "\n",
      "    accuracy                           0.21     20000\n",
      "   macro avg       0.13      0.13      0.07     20000\n",
      "weighted avg       0.16      0.21      0.12     20000\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "               feature  importance\n",
      "2           click_rate        1458\n",
      "0                 hour        1308\n",
      "7      std_pos_clicked        1243\n",
      "4    avg_pos_clicked_1        1156\n",
      "6    max_pos_clicked_1        1018\n",
      "5    min_pos_clicked_1         798\n",
      "29           page_id_1         652\n",
      "30           page_id_2         651\n",
      "28           page_id_0         650\n",
      "34           page_id_6         610\n",
      "31           page_id_3         609\n",
      "32           page_id_4         588\n",
      "33           page_id_5         510\n",
      "35           page_id_7         499\n",
      "37           page_id_9         454\n",
      "36           page_id_8         451\n",
      "13       std_pos_added         428\n",
      "38          page_id_10         409\n",
      "19  std_pos_wishlisted         364\n",
      "10     avg_pos_added_1         362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_age = 'purchasing_power'\n",
    "\n",
    "\n",
    "X = encoded_df[features]\n",
    "y = encoded_df[target_age]\n",
    "\n",
    "\n",
    "num_classes = y.nunique()\n",
    "print(f\"Number of unique age levels (classes): {num_classes}\")\n",
    "\n",
    "\n",
    "#  Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nOriginal training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Original training class distribution:\\n{y_train.value_counts().sort_index()}\")\n",
    "print(f\"\\nTest set shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"Test set class distribution:\\n{y_test.value_counts().sort_index()}\")\n",
    "\n",
    "\n",
    "#  Apply SMOTE to the Training Data \n",
    "print(\"\\nApplying SMOTE to the training data...\")\n",
    "\n",
    "\n",
    "min_class_size = y_train.value_counts().min()\n",
    "safe_k_neighbors = max(1, min_class_size - 1) \n",
    "\n",
    "print(f\"Smallest class size in training set: {min_class_size}. Setting SMOTE k_neighbors={safe_k_neighbors}\")\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=safe_k_neighbors)\n",
    "\n",
    "try:\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"\\nResampled training set shape: X={X_train_res.shape}, y={y_train_res.shape}\")\n",
    "    print(f\"Resampled training class distribution:\\n{pd.Series(y_train_res).value_counts().sort_index()}\") \n",
    "    print(\"SMOTE applied successfully.\")\n",
    "    use_resampled_data = True\n",
    "except ValueError as e:\n",
    "    print(f\"\\nSMOTE Error: {e}\")\n",
    "    print(\"Could not apply SMOTE (likely too few samples in a minority class).\")\n",
    "    print(\"Proceeding with original training data. Consider adding 'class_weight=\\'balanced\\'' back to LGBMClassifier if using original data.\")\n",
    "    X_train_res, y_train_res = X_train, y_train \n",
    "    use_resampled_data = False\n",
    "\n",
    "\n",
    "#  Initialize and Train LightGBM Model (without class_weight) \n",
    "# Use slightly increased patience and estimators as SMOTE might need more training\n",
    "lgbm_classifier = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=num_classes,\n",
    "    metric='multi_logloss',\n",
    "    n_estimators=2000,          \n",
    "    learning_rate=0.09,\n",
    "    num_leaves=31,               \n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1\n",
    "    \n",
    ")\n",
    "\n",
    "# Add class_weight back if SMOTE failed and we fell back to original data\n",
    "if not use_resampled_data:\n",
    "    print(\"\\nSMOTE failed, adding class_weight='balanced' to the model.\")\n",
    "    lgbm_classifier.set_params(class_weight='balanced')\n",
    "\n",
    "\n",
    "print(f\"\\nTraining LightGBM model {'on RESAMPLED data' if use_resampled_data else 'on ORIGINAL data (with weighting if SMOTE failed)'}...\")\n",
    "\n",
    "# Train the model using the (potentially) resampled training data\n",
    "lgbm_classifier.fit(\n",
    "    X_train_res, y_train_res,\n",
    "    eval_set=[(X_test, y_test)], \n",
    "    eval_metric='multi_logloss',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=150, verbose=True)] # Increased patience\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "\n",
    "# Make Predictions on the Original Test Set \n",
    "print(\"\\nMaking predictions on the test set...\")\n",
    "y_pred = lgbm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the Model \n",
    "print(\"\\nEvaluating the model...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nTest Set Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (Micro): {f1_micro:.4f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\nFeature Importances:\")\n",
    "  \n",
    "if isinstance(X_train_res, np.ndarray):\n",
    "    feature_names = X_train.columns \n",
    "else:\n",
    "     feature_names = X_train_res.columns \n",
    "\n",
    "feature_imp = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': lgbm_classifier.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_imp.head(20)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
